{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpZ7BYx3OOiXhkGCx7Sb0i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maberf/colabs/blob/main/fundamentus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "from time import sleep\n",
        "from IPython.display import display\n",
        "\n",
        "HEADERS = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"}"
      ],
      "metadata": {
        "id": "W_HfPwB-0Y_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scraperFundamentus (tickers):\n",
        "    \"\"\"\n",
        "    scraper Fundamentus\n",
        "    \"https://www.fundamentus.com.br/detalhes.php?papel={query_tic}\"\n",
        "    - Run for a list of tickers (e.g., [\"PETR4\"])\n",
        "    return\n",
        "    [type]: [pandas.core.frame.DataFrame]\n",
        "    \"\"\"\n",
        "\n",
        "    # Remove \".SA\" from stock dataframe tickers\n",
        "    tickersadjusted = [nome.replace('.SA', '') for nome in tickers]\n",
        "    # Remove \"^BVSP\" ticker\n",
        "    if \"^BVSP\" in tickersadjusted:\n",
        "        tickersadjusted.remove(\"^BVSP\")\n",
        "    print(tickersadjusted)\n",
        "\n",
        "    # ---------- utilities ----------\n",
        "    def parse_brazil_number(s):\n",
        "        if s is None:\n",
        "            return None\n",
        "        if isinstance(s, (int, float)):\n",
        "            return float(s)\n",
        "        st = str(s).strip()\n",
        "        if st in (\"\", \"-\", \"n/a\", \"na\"):\n",
        "            return None\n",
        "        st = st.replace(\"\\xa0\", \" \").strip()\n",
        "        if \"%\" in st:\n",
        "            st = st.replace(\"%\", \"\")\n",
        "        st = st.replace(\"R$\", \"\").strip()\n",
        "        # if it's text like 'PN' or 'ON', return as-is\n",
        "        if re.fullmatch(r'[A-Za-z\\.\\s]+', st) and not re.search(r'\\d', st):\n",
        "            return st\n",
        "        try:\n",
        "            if \".\" in st and \",\" in st:\n",
        "                return float(st.replace(\".\", \"\").replace(\",\", \".\"))\n",
        "            if \",\" in st and \".\" not in st:\n",
        "                return float(st.replace(\",\", \".\"))\n",
        "            if \".\" in st and \",\" not in st:\n",
        "                return float(st.replace(\".\", \"\"))\n",
        "            return float(st)\n",
        "        except:\n",
        "            return st\n",
        "\n",
        "    def extract_label_value_pairs_from_tr(tr):\n",
        "        cells = [c.get_text(\" \", strip=True) for c in tr.find_all(['td','th'])]\n",
        "        pairs = []\n",
        "        i = 0\n",
        "        n = len(cells)\n",
        "        while i < n:\n",
        "            label = cells[i].strip()\n",
        "            if label == \"\":\n",
        "                i += 1\n",
        "                continue\n",
        "            j = i + 1\n",
        "            while j < n and cells[j].strip() == \"\":\n",
        "                j += 1\n",
        "            if j >= n:\n",
        "                break\n",
        "            value = cells[j].strip()\n",
        "            label_norm = re.sub(r'[:\\s]+$', '', label)\n",
        "            pairs.append((label_norm, value))\n",
        "            i = j + 1\n",
        "        return pairs\n",
        "\n",
        "    # ---------- label mapping (kept from working code) ----------\n",
        "    LABEL_MAP = [\n",
        "        (r'^(papel|ticker)$', 'ticker'),\n",
        "        (r'cotac', 'cotacao'),\n",
        "        (r'data.*ult', 'data_ultima_cotacao'),\n",
        "        (r'min 52', 'min_52_sem'),\n",
        "        (r'max 52', 'max_52_sem'),\n",
        "        (r'vol .*2m|vol .*med', 'vol_med_2m'),\n",
        "        (r'^setor$', 'setor'),\n",
        "        (r'^subsetor$', 'subsetor'),\n",
        "        (r'valor de mercado|valor mercado', 'valor_mercado'),\n",
        "        (r'valor da firma|valor firma', 'valor_firma'),\n",
        "        (r'n(ro|º)|n(ro|º).*a[cç]oes|número.*a[cç]oes|nro.*a[cç]oes', 'nro_acoes'),\n",
        "        (r'p\\/l|p\\.?\\/l', 'pl'),\n",
        "        (r'lpa', 'lpa'),\n",
        "        (r'p\\/vp|p\\.?\\/vp', 'p_vp'),\n",
        "        (r'vpa', 'vpa'),\n",
        "        (r'marg.*ebit', 'marg_ebit'),\n",
        "        (r'p\\/ebit|p\\.?\\/ebit', 'p_ebit'),\n",
        "        (r'marg.*brut|margem.*bruta', 'marg_bruta'),\n",
        "        (r'psr', 'psr'),\n",
        "        (r'^ebit$', 'ebit'),\n",
        "        (r'p_?ativos|p\\/ativos', 'p_ativos'),\n",
        "        (r'marg.*liquida|margem.*liquida', 'marg_liquida'),\n",
        "        (r'p[_\\s]?cap[_\\s]?giro|p cap giro', 'p_cap_giro'),\n",
        "        (r'p[_\\s]?ativ[_\\s]?circ[_\\s]?liq', 'p_ativ_circ_liq'),\n",
        "        (r'roic', 'roic'),\n",
        "        (r'div.*yield|dividend.*yield', 'dividend_yield'),\n",
        "        (r'roe', 'roe'),\n",
        "        (r'ev.*ebitda|ev / ebitda', 'ev_ebitda'),\n",
        "        (r'liquidez corr|liquidez_corr|liquidez', 'liquidez_corr'),\n",
        "        (r'ev.*ebit|ev / ebit', 'ev_ebit'),\n",
        "        (r'div br.*patrim|div br patrim', 'div_br_patrim'),\n",
        "        (r'cres.*rec|cres_rec_5a', 'cres_rec_5a'),\n",
        "        (r'giro.*ativo|giro_ativos', 'giro_ativos'),\n",
        "        (r'^ativo$', 'ativo'),\n",
        "        (r'disponibilidades', 'disponibilidades'),\n",
        "        (r'ativo circulante|ativo_circulante', 'ativo_circulante'),\n",
        "        (r'div.*bruta', 'div_bruta'),\n",
        "        (r'div.*l[ií]quida', 'div_liquida'),\n",
        "        (r'patrim(o|ô)nio', 'patrimonio_liquido'),\n",
        "        (r'receita liquida', 'receita_liquida_12m'),\n",
        "        (r'lucro l[ií]quido', 'lucro_liquido_12m'),\n",
        "        (r'empresa', 'empresa'),\n",
        "        (r'oscila', 'oscilacoes'),\n",
        "        (r'tipo', 'tipo')\n",
        "    ]\n",
        "\n",
        "    def normalize_label(label):\n",
        "        lab = label.lower().strip()\n",
        "        trans = str.maketrans(\"áàãâéêíóôõúüç\",\"aaaaeeiooouuc\")\n",
        "        lab_no = lab.translate(trans)\n",
        "        for pat, std in LABEL_MAP:\n",
        "            if re.search(pat, lab_no):\n",
        "                return std\n",
        "        s = re.sub(r'[:\\.\\-\\/\\(\\)]', ' ', lab_no)\n",
        "        s = re.sub(r'[^0-9a-z\\s]', '', s)\n",
        "        s = re.sub(r'\\s+', '_', s).strip('_')\n",
        "        return s if s else label.lower()\n",
        "\n",
        "    # ---------- page parsing ----------\n",
        "    def parse_fundamentus_page(html_text):\n",
        "        soup = BeautifulSoup(html_text, \"html.parser\")\n",
        "        raw = {}\n",
        "        for table in soup.find_all('table'):\n",
        "            for tr in table.find_all('tr'):\n",
        "                pairs = extract_label_value_pairs_from_tr(tr)\n",
        "                for label, value in pairs:\n",
        "                    if not label:\n",
        "                        continue\n",
        "                    # prioritize first non-empty\n",
        "                    if label in raw and raw[label] in (None, \"\", \"-\") and value:\n",
        "                        raw[label] = value\n",
        "                    else:\n",
        "                        raw[label] = value\n",
        "\n",
        "        normalized = {}\n",
        "        for k, v in raw.items():\n",
        "            std = normalize_label(k)\n",
        "            parsed = parse_brazil_number(v)\n",
        "            normalized[std] = parsed\n",
        "\n",
        "        return normalized\n",
        "\n",
        "    # ---------- main function ----------\n",
        "    def get_many_tickers_fundamentus_df(tickers, pause=0.6):\n",
        "        session = requests.Session()\n",
        "        session.headers.update(HEADERS)\n",
        "        rows = []\n",
        "        cols_union = set()\n",
        "\n",
        "        for orig_tic in tickers:\n",
        "            # normalize ticker for query: remove '.SA' and leading '^'\n",
        "            query_tic = orig_tic.split('.')[0].lstrip('^').upper()\n",
        "            url = f\"https://www.fundamentus.com.br/detalhes.php?papel={query_tic}\"\n",
        "            r = session.get(url, timeout=15)\n",
        "            r.raise_for_status()\n",
        "            info = parse_fundamentus_page(r.text)\n",
        "            # keep original requested ticker (for traceability)\n",
        "            info['ticker'] = orig_tic\n",
        "            rows.append(info)\n",
        "            cols_union.update(info.keys())\n",
        "            sleep(pause)\n",
        "\n",
        "        # build DataFrame (columns sorted by union)\n",
        "        cols = ['ticker'] + sorted([c for c in cols_union if c != 'ticker'])\n",
        "        df = pd.DataFrame(rows, columns=cols)\n",
        "\n",
        "        # ----- Remove requested columns (oscillations, dates, etc.) -----\n",
        "        drop_patterns = re.compile(r'(oscil|dia\\b|mes\\b|30\\b|2020|2021|2022|2023|2024|2025)', re.I)\n",
        "        df = df[[c for c in df.columns if not drop_patterns.search(c)]]\n",
        "\n",
        "        # ----- Field Empresa: capitalize while keeping ON, PN, N1, N2, NM uppercase -----\n",
        "        if 'empresa' in df.columns:\n",
        "            def format_empresa(nome):\n",
        "                if not isinstance(nome, str) or nome.strip() == \"\":\n",
        "                    return nome\n",
        "                partes = nome.split()\n",
        "                out = []\n",
        "                for p in partes:\n",
        "                    pu = p.upper()\n",
        "                    if pu in ['ON','PN','N1','N2','NM']:\n",
        "                        out.append(pu)\n",
        "                    else:\n",
        "                        out.append(p.capitalize())\n",
        "                return \" \".join(out)\n",
        "            df['empresa'] = df['empresa'].apply(format_empresa)\n",
        "\n",
        "        # ----- Number conversion/format: values > 1000 -> integers, avoid scientific notation -----\n",
        "        for col in df.columns:\n",
        "            ser = pd.to_numeric(df[col], errors='coerce')\n",
        "            if ser.notna().any():\n",
        "                # apply: if abs(x) >= 1000 convert to int(round(x)) and store as object to avoid scientific notation\n",
        "                def conv(x):\n",
        "                    if pd.isna(x):\n",
        "                        return x\n",
        "                    try:\n",
        "                        if abs(x) >= 1000:\n",
        "                            return int(round(x))\n",
        "                        # keep floats (indicators) with 2 decimals when not large integers\n",
        "                        if float(x).is_integer():\n",
        "                            return int(x)\n",
        "                        return float(x)\n",
        "                    except:\n",
        "                        return x\n",
        "                df[col] = ser.apply(conv)\n",
        "                df[col] = df[col].astype(object)\n",
        "            else:\n",
        "                df[col] = df[col].astype(object)\n",
        "\n",
        "        # ----- Reorder columns as requested (best-effort) -----\n",
        "        desired_order = [\n",
        "            \"ticker\",\"cotacao\",\"data_ultima_cotacao\",\"min_52_sem\",\"max_52_sem\",\"vol_med_2m\",\n",
        "            \"setor\",\"valor_mercado\",\"valor_firma\",\"nro_acoes\",\"pl\",\"lpa\",\"p_vp\",\"vpa\",\"p_ebit\",\n",
        "            \"marg_bruta\",\"psr\",\"marg_ebit\",\"p_ativos\",\"marg_liquida\",\"p_cap_giro\",\"p_ativ_circ_liq\",\n",
        "            \"roic\",\"dividend_yield\",\"roe\",\"ev_ebitda\",\"liquidez_corr\",\"ev_ebit\",\"div_br_patrim\",\n",
        "            \"cres_rec_5a\",\"giro_ativos\",\"ativo\",\"disponibilidades\",\"ativo_circulante\",\"div_bruta\",\n",
        "            \"div_liquida\",\"patrimonio_liquido\",\"receita_liquida_12m\",\"ebit\",\"lucro_liquido_12m\"\n",
        "        ]\n",
        "        final_cols = []\n",
        "        existing = list(df.columns)\n",
        "        used = set()\n",
        "        for want in desired_order:\n",
        "            match = None\n",
        "            if want in existing:\n",
        "                match = want\n",
        "            else:\n",
        "                for c in existing:\n",
        "                    if c in used:\n",
        "                        continue\n",
        "                    cl = c.lower()\n",
        "                    if want.replace('_',' ') in cl or all(tok in cl for tok in want.split('_') if tok):\n",
        "                        match = c\n",
        "                        break\n",
        "            if match:\n",
        "                final_cols.append(match)\n",
        "                used.add(match)\n",
        "        for c in existing:\n",
        "            if c not in used:\n",
        "                final_cols.append(c)\n",
        "        fundamentus = df.reindex(columns=final_cols)\n",
        "\n",
        "        # format display options to avoid scientific notation\n",
        "        pd.set_option('display.max_columns', None)\n",
        "        pd.set_option('display.width', 400)\n",
        "        pd.set_option('display.float_format', lambda x: '%.0f' % x if abs(x) >= 1000 else ('%.2f' % x))\n",
        "\n",
        "        return fundamentus\n",
        "\n",
        "    df = get_many_tickers_fundamentus_df(tickersadjusted)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "xopmx0AoeFiF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}