{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maberf/colabs/blob/main/Portfolio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ##### PORTFOLIO INVESTOR CODE #####\n",
        "#\n",
        "# GOOGLE SHEETS - Code to upload data in Google Sheets to support investiments decisions. The Google Sheets can be adjusting according user desire, but its location should be adjusted in code also.\n",
        "# Quotes  - Google Sheets file name with all sheets inside\n",
        "# Stockvar - Sheet with data with B3 brazilian stocks history series in BRL\n",
        "# RealSatevar - Sheet with data with B3 brazilian REITs history series in BRL\n",
        "# StockUSvar - Sheet with data with US stocks history series in USD\n",
        "# ETFUSvar - Sheet with data with US ETFs history series in USD\n",
        "# RealSateUSvar - Sheet with data with US REITs history series in USD\n",
        "# Portfolio - Sheet with portfolio considering assets in list in BRL. US assets are converted in BRL.\n",
        "# YFStockUS - Yahoo Finance provide US assets fundamentalist informations directly, but not in case o B3 assets.\n",
        "# Fundamentus - In B3 case, a new code is necessary scraping informations from specialized sites such as https://www.fundamentus.com.br . This is in fundamentus python code.\n",
        "# Quote - It is suggested create a Google Sheets sheet in Quotes file which consolidate all quotes and where you can import data from other sheets. It is suggested to use Google Finance in this sheets once the quototion update is faster than in code running.\n",
        "# Discounted Cash Flow asset evaluations can be done directly in this Google Sheets Quote sheet.\n",
        "#\n",
        "# The lists with the tickers and other informations should be filled directly in the code where there are INSERT OR ADJUST HERE lines.\n",
        "# IFIX - History series csv file with time desired period (2y, 3y, etc.) from https://br.investing.com/indices/bm-fbovespa-real-estate-ifix-historical-data should be downloaded to a Google Drive directory which is in the path in code.\n",
        "# FUNDS EXPLORER - Copy and paste date from https://www.fundsexplorer.com.br/ranking in a Google Drive directory excel file which is in the path in code. It is necessary to SELECT ALL COLUMNS in Funds Explorer website.\n",
        "# Before to run the code it is necessary to make these previous activities and insert the input data . Check the code below until the ENDING POINT TO MANUAL ACTIVITIES.\n",
        "# Verifiy data on thes files in case of code running problems.\n",
        "# During the code running it is necessary to allow access to Google. Necessary code access Google Drive where files are located and Google Sheets to upload the results."
      ],
      "metadata": {
        "id": "uDaN4LeB6Qd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVYwmuIWyMbm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "import yfinance as yf\n",
        "import os\n",
        "import datetime as dt\n",
        "from google.colab import drive\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "import gspread"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGQGCggjjF0F"
      },
      "outputs": [],
      "source": [
        "# Stock tickers - Insert here# Real Estate Invesments Trust tickers - INSERT OR ADJUST HERE\n",
        "# Try to mantain IBOV + 30 assets in alphabetical order to easly adjust google docs spreadsheet\n",
        "tickers = ['^BVSP','ABEV3.SA','BBAS3.SA','BBDC4.SA','BBSE3.SA','CMIN3.SA','CPFE3.SA','CPLE6.SA','ELET6.SA','FLRY3.SA','ITUB4.SA','IVVB11.SA','JHSF3.SA','KLBN11.SA','MBRF3.SA','LEVE3.SA','LREN3.SA','NEOE3.SA','PETR4.SA','POMO4.SA','QQQI11.SA','RECV3.SA','RENT3.SA','SBSP3.SA','TGMA3.SA','TIMS3.SA','TUPY3.SA','VALE3.SA','VIVA3.SA','VIVT3.SA','WEGE3.SA']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7mFM3kZa37g"
      },
      "outputs": [],
      "source": [
        "# Real Estate Investments Trust tickers - INSERT OR ADJUST HERE\n",
        "# Try to mantain IFIX + 20 assets in alphabetical order to easly adjust google docs spreadsheet\n",
        "# IFIX here only to a space in dataframe, yahoo finance return IFIX.SA maximum 5 days. IFIX should be calculated downloading an Investing.com csv file history and it must be uploaded in personal Google Drive. This code read it.\n",
        "tickerr = ['IFIX.SA','BTLG11.SA','HGCR11.SA','HGBS11.SA','HGRE11.SA','HGRU11.SA','HSLG11.SA','HSML11.SA','HTMX11.SA','JSAF11.SA','JFLL11.SA','KNCA11.SA','KNHF11.SA','KNIP11.SA','MXRF11.SA','MFII11.SA','SAPI11.SA','TGAR11.SA','TRXF11.SA','VGHF11.SA','VISC11.SA']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# US Stocks tickers - INSERT OR ADJUST HERE\n",
        "# Try to mantain SP500 + USDBRL + 30 assets in alphabetical order to easly adjust google docs spreadsheet\n",
        "tickersus = ['^GSPC','USDBRL=X','AAPL','AMZN','ASML','BAC','BKNG','BMY','BRK-B','CRWD','EXC','GOOG','HALO','JNJ','JPM','KMB','KO','LLY','META','MRK','MSFT','NOW','NVDA','PFE','PLTR','RIO','T','TSLA','TSM','V','XOM','WMT']"
      ],
      "metadata": {
        "id": "3oGcgtj8QVcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# US ETFs tickers - INSERT OR ADJUST HERE\n",
        "# Try to mantain SP500 + USDBRL + 10 assets in alphabetical order to easly adjust google docs spreadsheet\n",
        "tickereus = ['^GSPC','USDBRL=X','FBTC','JEPI','HACK', 'IVV','SCHD','SOXX','SPY','TLT','SMH','TFLO']"
      ],
      "metadata": {
        "id": "XLzaMHIfsuyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# US ETFs REITS tickers - INSERT OR ADJUST HERE\n",
        "# Try to mantain SP500 + USDBRL + 10 assets in alphabetical order to easly adjust google docs spreadsheet\n",
        "tickerrus = ['USRT','USDBRL=X','O','STAG','ADC', 'LTC','SLG','WELL','PLD','AMT','EQIX','SPG']"
      ],
      "metadata": {
        "id": "TxxerJodwtXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Portfolio tickers - INSERT OR ADJUST HERE\n",
        "tickerport = ['^BVSP','USDBRL=X','AMZN','BBSE3.SA','BRK-B','CPFE3.SA','ELET6.SA','FBTC','HTMX11.SA','JHSF3.SA','JSAF11.SA','KMB','MRK','MSFT','PETR4.SA','POMO4.SA','SAPI11.SA','SCHD','TFLO','TGAR11.SA','TRXF11.SA','VALE3.SA']\n",
        "# Portfolio tickers weight - INSERT OR ADJUST HERE IN THE SAME ORDER!\n",
        "weightport = [0.000, 0.000, 5.081, 7.509, 10.812, 0.000, 8.292, 2.714, 5.311, 0.000, 6.269, 3.388, 3.388, 3.388, 13.885, 0.000, 6.410, 1.355, 3.389, 4.908, 13.882, 0.000]\n",
        "# Portfolio tickers expected returns - INSERT OR ADJUST HERE IN THE SAME ORDER!\n",
        "# IBOV (^BVSP) and USD (USDBRL=X) MUST always be zero!\n",
        "expretport = [0.0, 8.0, 23.9, 18.5, 18.5, 2.7, 6.0, 25.9, 20.5, 25.3, 28.1, 19.8, 24.6, 21.5, 28.4, 13.8, 17.1, 8.6, 8.6, 22.1, 19.4, 5.8]\n",
        "# Portfolio assets limits - INSERT OR ADJUST HERE IN THE SAME ORDER!\n",
        "# IBOV (^BVSP) and USD (USDBRL=X) MUST always be zero!\n",
        "limitsassetsport = [0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 5.0, 5.0, 10.0, 5.0, 6.0, 5.0, 5.0, 5.0, 15.0, 5.0, 6.0, 5.0, 5.0, 5.0, 15.0, 10.0]\n",
        "fatorcorr = 0.90987 # CORRECTION FACTOR to adjusts weights just to variable incomes assets discounting other ones such as risk free incomes. It is to simplify comparision directly in your investment spreadsheet. If it is only varible incomes, correction factor is 1.0.\n",
        "limitsassetsport = [x * fatorcorr for x in limitsassetsport]\n",
        "# Print just to verify lists lengths\n",
        "print(len(tickerport))\n",
        "print(len(weightport))\n",
        "print(len(expretport))\n",
        "print(len(limitsassetsport))\n"
      ],
      "metadata": {
        "id": "lbxAtnEFV3ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Risk free rate BRAZIL in percentage - INSERT OR ADJUST HERE\n",
        "riskfree = 13.88"
      ],
      "metadata": {
        "id": "uWISQcWhrNVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target Sharpe in percentage of Sharpe Maximum - INSERT OR ADJUST HERE\n",
        "target_per = 85.0"
      ],
      "metadata": {
        "id": "mihd9qM96Br-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Portfolio dataframe creation\n",
        "portfolio = pd.DataFrame({'Ticker': tickerport, 'W': weightport, 'RetE%':expretport})"
      ],
      "metadata": {
        "id": "94SgPSqR0Fi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excluding .SA, renaming ^BVSP to IBOV and USDBRL=X to USDBRL\n",
        "portfolio['Ticker'] = portfolio['Ticker'].str.replace('.SA', '', regex=False)\n",
        "portfolio['Ticker'] = portfolio['Ticker'].str.replace('^BVSP', 'IBOV', regex=False)\n",
        "portfolio['Ticker'] = portfolio['Ticker'].str.replace('USDBRL=X', 'USDBRL', regex=False)\n",
        "# display(portfolio)"
      ],
      "metadata": {
        "id": "y5BMLvAG2F8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsdtOFcYy8Xx"
      },
      "outputs": [],
      "source": [
        "# Load tickers history prices in a dataframe considering a certain period of time - ADJUST HERE, default 1 year (1y)\n",
        "# Sometimes some ticker has problems in yahoo finance. If it happens, close the session and try again. Or change the ticker, because problem in one ticker will cause problem in all code running.\n",
        "# Check success download completed to all dataframes, otherwise the code will broke in next lines.\n",
        "dfs = yf.download(tickers, period='2y', auto_adjust=True)['Close']\n",
        "dfr = yf.download(tickerr, period='2y', auto_adjust=True)['Close']\n",
        "dfsus = yf.download(tickersus, period='2y', auto_adjust=True)['Close']\n",
        "dfeus = yf.download(tickereus, period='2y', auto_adjust=True)['Close']\n",
        "dfrus = yf.download(tickerrus, period='2y', auto_adjust=True)['Close']\n",
        "dfport = yf.download(tickerport, period='2y', auto_adjust=True)['Close']\n",
        "# Remove timezone from index\n",
        "dfs.index = pd.to_datetime(dfs.index).tz_localize(None)\n",
        "dfr.index = pd.to_datetime(dfr.index).tz_localize(None)\n",
        "dfsus.index = pd.to_datetime(dfsus.index).tz_localize(None)\n",
        "dfeus.index = pd.to_datetime(dfeus.index).tz_localize(None)\n",
        "dfrus.index = pd.to_datetime(dfrus.index).tz_localize(None)\n",
        "dfport.index = pd.to_datetime(dfport.index).tz_localize(None)\n",
        "# display(dfs)\n",
        "# display(dfr)\n",
        "# display(dfeus)\n",
        "# display(dfrus)\n",
        "# display(dfport)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IFIX historic series from Investing.com to be appended in real state dataframe dfr - https://br.investing.com/indices/bm-fbovespa-real-estate-ifix-historical-data - MAKE THIS ACTIVITY\n",
        "# Download the file from site and copy to your google drive. Rename de file as history.csv. Adjust the path below in \" ifixfile = .... \" command line according your file location.\n",
        "# Google Drive mounth\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "# File path on Google Drive - Download the file and upload to Financas folder in Google Drive. Rename the path according file name uploaded.\n",
        "ifixfile = '/content/drive/MyDrive/Financas/history.csv'\n",
        "# File csv to dataframe converting quote to float\n",
        "ifix = pd.read_csv(ifixfile, thousands = '.', decimal = ',', dtype = {'Último':np.float64})\n",
        "# Excluding and rename columns\n",
        "ifix = ifix.drop(columns=['Abertura', 'Máxima', 'Mínima', 'Vol.', 'Var%'])\n",
        "ifix = ifix.rename(columns={'Data': 'Date', 'Último': 'IFIX.SA'})\n",
        "# Date format in Date column\n",
        "ifix['Date'] = pd.to_datetime(ifix['Date'], format='%d%m%Y', errors='coerce')\n",
        "ifix.set_index('Date', inplace=True)\n",
        "# Solve eventual duplicated registers, grouped by mean\n",
        "ifix = ifix.groupby(level=0).mean()\n",
        "# display(ifix)"
      ],
      "metadata": {
        "id": "OIILfCdkKEMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Go to Funds Explorer Table in https://www.fundsexplorer.com.br/ranking  - MAKE THIS ACTIVITY\n",
        "# Manually select all columns in web page and paste all data AS VALUES ONLY in a NEW Excel File sheet.\n",
        "# Save the file with the name fundsexplorer.xlsx in a folder called Financas (or in another preferable path, adjusting the path below)\n",
        "fundsexplorerfile = '/content/drive/MyDrive/Financas/fundsexplorer.xlsx'\n",
        "# Excel file reading\n",
        "fundsexplorer = pd.read_excel(fundsexplorerfile)\n",
        "#display(fundsexplorer)\n",
        "# The sequence of FUNDS EXPLORER ROUTINE, see at the end of the code."
      ],
      "metadata": {
        "id": "san5iymu-zXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ENDING POINT TO MANUAL ACTIVITIES. The code should run after this point. Permission to Google Drive access can be required during code running."
      ],
      "metadata": {
        "id": "OJdHGCI5_BDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace dfr dataframe by ifix values by index key (date)\n",
        "dfr.update(ifix)\n",
        "# display(dfr)"
      ],
      "metadata": {
        "id": "mdikcSplKQUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excluding .SA, renaming ^BVSP to IBOV, ^GSPC to SP500\n",
        "dfs.columns = [col.replace('.SA', '') for col in dfs.columns]\n",
        "dfs.columns = [col.replace('^BVSP', 'IBOV') for col in dfs.columns]\n",
        "dfr.columns = [col.replace('.SA', '') for col in dfr.columns]\n",
        "dfsus.columns = [col.replace('^GSPC', 'SP500') for col in dfsus.columns]\n",
        "dfsus.columns = [col.replace('USDBRL=X', 'USDBRL') for col in dfsus.columns]\n",
        "dfeus.columns = [col.replace('^GSPC', 'SP500') for col in dfeus.columns]\n",
        "dfeus.columns = [col.replace('USDBRL=X', 'USDBRL') for col in dfeus.columns]\n",
        "# dfrus.columns = [col.replace('^GSPC', 'SP500') for col in dfrus.columns]\n",
        "dfrus.columns = [col.replace('USDBRL=X', 'USDBRL') for col in dfrus.columns]\n",
        "dfport.columns = [col.replace('.SA', '') for col in dfport.columns]\n",
        "dfport.columns = [col.replace('^BVSP', 'IBOV') for col in dfport.columns]\n",
        "dfport.columns = [col.replace('USDBRL=X', 'USDBRL') for col in dfport.columns]"
      ],
      "metadata": {
        "id": "oHbSRWbA7xsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDCUEPHVJjoL"
      },
      "outputs": [],
      "source": [
        "# Other conformations such as ascending order and the market indexes in the first column\n",
        "dfs = dfs[sorted(dfs.columns)]\n",
        "dfr = dfr[sorted(dfr.columns)]\n",
        "dfsus = dfsus[sorted(dfsus.columns)]\n",
        "dfeus = dfeus[sorted(dfeus.columns)]\n",
        "dfrus = dfrus[sorted(dfrus.columns)]\n",
        "dfport = dfport[sorted(dfport.columns)]\n",
        "dfs = dfs[['IBOV'] + [col for col in dfs.columns if col != 'IBOV']]\n",
        "dfr = dfr[['IFIX'] + [col for col in dfr.columns if col != 'IFIX']]\n",
        "dfsus = dfsus[['SP500', 'USDBRL'] + [col for col in dfsus.columns if col not in ['SP500', 'USDBRL']]]\n",
        "dfeus = dfeus[['SP500', 'USDBRL'] + [col for col in dfeus.columns if col not in ['SP500', 'USDBRL']]]\n",
        "dfrus = dfrus[['USRT', 'USDBRL'] + [col for col in dfrus.columns if col not in ['USRT', 'USDBRL']]]\n",
        "dfport = dfport[['IBOV', 'USDBRL'] + [col for col in dfport.columns if col not in ['IBOV', 'USDBRL']]]\n",
        "# Here dataframes should be ready for calculations. It will be made and uploaded in dfxvar dataframes later.\n",
        "# display(dfs)\n",
        "# display(dfr)\n",
        "# display(dfsus)\n",
        "# display(dfeus)\n",
        "# display(dfrus)\n",
        "# display(dfport)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Timeline harmonization, same period of time\n",
        "common_idx = (\n",
        "    dfs.index\n",
        "    .intersection(dfr.index)\n",
        "    .intersection(dfsus.index)\n",
        "    .intersection(dfeus.index)\n",
        "    .intersection(dfrus.index)\n",
        "    .intersection(dfport.index)\n",
        ")\n",
        "\n",
        "# Reindex e preencher (sem warnings)\n",
        "dfs = dfs.reindex(common_idx).ffill()\n",
        "dfr = dfr.reindex(common_idx).ffill()\n",
        "dfsus = dfsus.reindex(common_idx).ffill()\n",
        "dfeus = dfeus.reindex(common_idx).ffill()\n",
        "dfrus = dfrus.reindex(common_idx).ffill()\n",
        "dfport = dfport.reindex(common_idx).ffill()\n"
      ],
      "metadata": {
        "id": "KQgd3YPmLdZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Portfolio daframe in BRL\n",
        "# Multiply USA assets by USDBRL value (BRL quotation)\n",
        "#\n",
        "usd_sources = []\n",
        "for name in ('dfsus', 'dfeus', 'dfrus'):\n",
        "    if name in globals():\n",
        "        try:\n",
        "            df_src = globals()[name]\n",
        "            # consider only columns (tickers) of reference dataframe\n",
        "            usd_sources.extend(list(df_src.columns))\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "usd_set = set(usd_sources)\n",
        "\n",
        "# Identifies dfport columns that correspond to assets in USD (ignores the exchange rate column).\n",
        "cols_a_converter = [c for c in dfport.columns if c != 'USDBRL' and c in usd_set]\n",
        "\n",
        "# Performs the conversion (multiplies the price in USD by the USDBRL exchange rate line by line)\n",
        "for col in cols_a_converter:\n",
        "    # multiplication aligns indices; preserves NaNs where they exist.\n",
        "    dfport[col] = dfport[col].multiply(dfport['USDBRL'], axis=0)\n",
        "\n",
        "# Displayed result: which columns were converted and initial preview of dfport.\n",
        "if cols_a_converter:\n",
        "    print(f\"Convertidas para BRL (multiplicadas por dfport['USDBRL']): {cols_a_converter}\")\n",
        "else:\n",
        "    print(\"Nenhuma coluna de dfport foi identificada como cotada em USD (nenhuma conversão aplicada).\")\n",
        "\n",
        "# Show the first lines of the dfport for review.\n",
        "display(dfport.head())"
      ],
      "metadata": {
        "id": "my8oUiGH-TNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcgVC4D3YRGZ"
      },
      "outputs": [],
      "source": [
        "# Calculate daily variation\n",
        "dfsvar = dfs.pct_change()\n",
        "dfrvar = dfr.pct_change()\n",
        "dfsusvar = dfsus.pct_change()\n",
        "dfeusvar = dfeus.pct_change()\n",
        "dfrusvar = dfrus.pct_change()\n",
        "dfportvar = dfport.pct_change()\n",
        "# display(dfsvar)\n",
        "# display(dfrvar)\n",
        "# display(dfsusvar)\n",
        "# display(dfeusvar)\n",
        "# display(dfeusvar)\n",
        "# display(dfportvar)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Market Percentage Historic Return calculation and column add in output dataframes\n",
        "# CAGR – Compound Annual Growth Rate - calculation\n",
        "#\n",
        "def cagr_from_prices(series):\n",
        "    s = series.dropna()\n",
        "    if len(s) < 2:\n",
        "        return np.nan\n",
        "    total_return = s.iloc[-1] / s.iloc[0] - 1\n",
        "    n_days = len(s) - 1\n",
        "    # annualizes to 252 working days per year.\n",
        "    return (1 + total_return) ** (252 / n_days) - 1\n",
        "#\n",
        "# Stocks - Applies by column (each column = one ticker)\n",
        "cagr_series = dfs.apply(cagr_from_prices)  # Returns a fraction, e.g., 0.069 = 6.9%\n",
        "stockvar = cagr_series.mul(100).to_frame(name='RetH%')  # converts to %\n",
        "stockvar.index.name = 'Ticker'\n",
        "stockvar['RetH%'] = stockvar['RetH%'].round(1)\n",
        "# display(stockvar)\n",
        "#\n",
        "# Real State - Applies by column (each column = one ticker)\n",
        "cagr_series = dfr.apply(cagr_from_prices)  # Returns a fraction, e.g., 0.069 = 6.9%\n",
        "realstatevar = cagr_series.mul(100).to_frame(name='RetH%')  # converts to %\n",
        "realstatevar.index.name = 'Ticker'\n",
        "realstatevar['RetH%'] = realstatevar['RetH%'].round(1)\n",
        "# display(realstatevar)\n",
        "#\n",
        "# Stock US - Applies by column (each column = one ticker)\n",
        "cagr_series = dfsus.apply(cagr_from_prices)  # Returns a fraction, e.g., 0.069 = 6.9%\n",
        "stockusvar = cagr_series.mul(100).to_frame(name='RetH%')  # converts to %\n",
        "stockusvar.index.name = 'Ticker'\n",
        "stockusvar['RetH%'] = stockusvar['RetH%'].round(1)\n",
        "# display(stockusvar)\n",
        "#\n",
        "# ETF US - Applies by column (each column = one ticker)\n",
        "cagr_series = dfeus.apply(cagr_from_prices)  # Returns a fraction, e.g., 0.069 = 6.9%\n",
        "etfusvar = cagr_series.mul(100).to_frame(name='RetH%')  # converts to %\n",
        "etfusvar.index.name = 'Ticker'\n",
        "etfusvar['RetH%'] = etfusvar['RetH%'].round(1)\n",
        "# display(etfusvar)\n",
        "#\n",
        "# ETF REITS US - Applies by column (each column = one ticker)\n",
        "cagr_series = dfrus.apply(cagr_from_prices)  # Returns a fraction, e.g., 0.069 = 6.9%\n",
        "reitusvar = cagr_series.mul(100).to_frame(name='RetH%')  # converts to %\n",
        "reitusvar.index.name = 'Ticker'\n",
        "reitusvar['RetH%'] = reitusvar['RetH%'].round(1)\n",
        "# display(reitusvar)\n",
        "#\n",
        "# Portfolio - Aplica por coluna (cada coluna = um ticker)\n",
        "cagr_series = dfport.apply(cagr_from_prices)  # Returns a fraction, e.g., 0.069 = 6.9%\n",
        "portvar = cagr_series.mul(100).to_frame(name='RetH%')  # converts to %\n",
        "portvar.index.name = 'Ticker'\n",
        "portvar['RetH%'] = portvar['RetH%'].round(1)\n",
        "# display(portvar)"
      ],
      "metadata": {
        "id": "QTnKNYX_Ew1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dbp_7QIAZ2bh"
      },
      "outputs": [],
      "source": [
        "# Market return variance calculation\n",
        "vars = dfsvar.var()*252\n",
        "varr = dfrvar.var()*252\n",
        "varsus = dfsusvar.var()*252\n",
        "vareus = dfeusvar.var()*252\n",
        "varrus = dfrusvar.var()*252\n",
        "varport = dfportvar.var()*252\n",
        "# display(vars)\n",
        "# display(varr)\n",
        "# display(varsus)\n",
        "# display(vareus)\n",
        "# display(varrus)\n",
        "# display(varport)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Market risk calculation, in percentage (%). Add column in output dataframes\n",
        "stockvar['Risk%'] = dfsvar.std()*np.sqrt(252)*100\n",
        "stockvar['Risk%'] = stockvar['Risk%'].round(0)\n",
        "realstatevar['Risk%'] = dfrvar.std()*np.sqrt(252)*100\n",
        "realstatevar['Risk%'] = realstatevar['Risk%'].round(0)\n",
        "stockusvar['Risk%'] = dfsusvar.std()*np.sqrt(252)*100\n",
        "stockusvar['Risk%'] = stockusvar['Risk%'].round(0)\n",
        "etfusvar['Risk%'] = dfeusvar.std()*np.sqrt(252)*100\n",
        "etfusvar['Risk%'] = etfusvar['Risk%'].round(0)\n",
        "reitusvar['Risk%'] = dfrusvar.std()*np.sqrt(252)*100\n",
        "reitusvar['Risk%'] = reitusvar['Risk%'].round(0)\n",
        "portvar['Risk%'] = dfportvar.std()*np.sqrt(252)*100\n",
        "portvar['Risk%'] = portvar['Risk%'].round(0)\n",
        "# display(stockvar)\n",
        "# display(realstatevar)\n",
        "# display(stockusvar)\n",
        "# display(etfusvar)\n",
        "# display(reitusvar)\n",
        "# display(portvar)"
      ],
      "metadata": {
        "id": "wa3KeoAjpuGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foFpvk98EV1M"
      },
      "outputs": [],
      "source": [
        "# Covariance calculation\n",
        "covs = dfsvar.cov()*252\n",
        "covr = dfrvar.cov()*252\n",
        "covsus = dfsusvar.cov()*252\n",
        "coveus = dfeusvar.cov()*252\n",
        "covrus = dfrusvar.cov()*252\n",
        "covport = dfportvar.cov()*252\n",
        "# display(covs)\n",
        "# display(covr)\n",
        "# display(covsus)\n",
        "# display(coveus)\n",
        "# display(covrus)\n",
        "# display(covport)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFGifgTrAoDA"
      },
      "outputs": [],
      "source": [
        "# Beta calculation\n",
        "betas = covs['IBOV']/vars['IBOV']\n",
        "betas = betas.round(3)\n",
        "betas.name = 'Beta'\n",
        "betar = covr['IFIX']/varr['IFIX']\n",
        "betar = betar.round(3)\n",
        "betar.name = 'Beta'\n",
        "betasus = covsus['SP500']/varsus['SP500']\n",
        "betasus = betasus.round(3)\n",
        "betasus.name = 'Beta'\n",
        "betaeus = coveus['SP500']/vareus['SP500']\n",
        "betaeus = betaeus.round(3)\n",
        "betaeus.name = 'Beta'\n",
        "betarus = covrus['USRT']/varrus['USRT']\n",
        "betarus = betarus.round(3)\n",
        "betarus.name = 'Beta'\n",
        "betaport = covport['IBOV']/varport['IBOV']\n",
        "betaport = betaport.round(3)\n",
        "betaport.name = 'Beta'\n",
        "# display(betas)\n",
        "# display(betar)\n",
        "# display(betasus)\n",
        "# display(betaeus)\n",
        "# display(betarus)\n",
        "# display(betaport)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding Beta to column output dataframes\n",
        "stockvar['Beta'] = betas\n",
        "realstatevar['Beta'] = betar\n",
        "stockusvar['Beta'] = betasus\n",
        "etfusvar['Beta'] = betaeus\n",
        "reitusvar['Beta'] = betarus\n",
        "portvar['Beta'] = betaport\n",
        "# display(stockvar)\n",
        "# display(realstatevar)\n",
        "# display(stockusvar)\n",
        "# display(etfusvar)\n",
        "# display(reitusvar)\n",
        "# display(portvar)"
      ],
      "metadata": {
        "id": "Zanbv1uJnfju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding Min to column output dataframes\n",
        "stockvar['Min'] = dfs.min()\n",
        "stockvar['Min'] = stockvar['Min'].round(2)\n",
        "realstatevar['Min'] = dfr.min()\n",
        "realstatevar['Min'] = realstatevar['Min'].round(2)\n",
        "stockusvar['Min'] = dfsus.min()\n",
        "stockusvar['Min'] = stockusvar['Min'].round(2)\n",
        "etfusvar['Min'] = dfeus.min()\n",
        "etfusvar['Min'] = etfusvar['Min'].round(2)\n",
        "reitusvar['Min'] = dfrus.min()\n",
        "reitusvar['Min'] = reitusvar['Min'].round(2)\n",
        "portvar['Min'] = dfport.min()\n",
        "portvar['Min'] = portvar['Min'].round(2)\n",
        "# display(stockvar)\n",
        "# display(realstatevar)\n",
        "# display(stockusvar)\n",
        "# display(etfusvar)\n",
        "# display(reitusvar)\n",
        "# display(portvar)"
      ],
      "metadata": {
        "id": "YnAEVEP1YD4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding Max to column output dataframes\n",
        "stockvar['Max'] = dfs.max()\n",
        "stockvar['Max'] = stockvar['Max'].round(2)\n",
        "realstatevar['Max'] = dfr.max()\n",
        "realstatevar['Max'] = realstatevar['Max'].round(2)\n",
        "stockusvar['Max'] = dfsus.max()\n",
        "stockusvar['Max'] = stockusvar['Max'].round(2)\n",
        "etfusvar['Max'] = dfeus.max()\n",
        "etfusvar['Max'] = etfusvar['Max'].round(2)\n",
        "reitusvar['Max'] = dfrus.max()\n",
        "reitusvar['Max'] = reitusvar['Max'].round(2)\n",
        "portvar['Max'] = dfport.max()\n",
        "portvar['Max'] = portvar['Max'].round(2)\n",
        "# display(stockvar)\n",
        "# display(realstatevar)\n",
        "# display(stockusvar)\n",
        "# display(etfusvar)\n",
        "# display(reitusvar)\n",
        "# display(portvar)"
      ],
      "metadata": {
        "id": "v4fdFkBNZ6Ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Organizing columns order and making Index column as index of dataframes\n",
        "stockvar = stockvar.reset_index()\n",
        "realstatevar = realstatevar.reset_index()\n",
        "stockusvar = stockusvar.reset_index()\n",
        "etfusvar = etfusvar.reset_index()\n",
        "reitusvar = reitusvar.reset_index()\n",
        "portvar = portvar.reset_index()\n",
        "# display(stockvar)\n",
        "# display(realstatevar)\n",
        "# display(stockusvar)\n",
        "# display(etfusvar)\n",
        "# display(reitusvar)\n",
        "# display(portvar)"
      ],
      "metadata": {
        "id": "YYMn4_w7vIg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FUNCTIONS TO CALCULATE PORTFOLIO PERFORMANCE, MAXIMUM SHARPE AND TARGET SHARPE\n",
        "# --- Usage example ---\n",
        "# Assuming you have df_returns (DataFrame) with log or simple returns, calculated daily/monthly:\n",
        "# mu = df_returns.mean().values           # average return per asset (compatible frequency)\n",
        "# cov = df_returns.cov().values           # covariance matrix\n",
        "# risk_free = 0.0                         # adjust according to your frequency (e.g., annual rate/252 for daily)\n",
        "#\n",
        "# res_max, w_max = max_sharpe_weights(mu, cov, riskfree)\n",
        "# print(\"Max Sharpe:\", portfolio_performance(w_max, mu, cov, risk_free)[2], \"weights:\", w_max)\n",
        "#\n",
        "# target = 1.2\n",
        "# res_tgt, w_tgt, info = weights_for_target_sharpe(mu, cov, target, riskfree)\n",
        "# print(\"Target result:\", info)\n",
        "# print(\"Weights:\", w_tgt)"
      ],
      "metadata": {
        "id": "UyjQhlsWK0KW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Portfolio dataframe assembling\n",
        "portfolio = pd.merge(portfolio, portvar, on='Ticker', how='inner')\n",
        "# firstsnames = ['IBOV','USDBRL']\n",
        "firstsnames = ['IBOV', 'USDBRL']\n",
        "portfolio.iloc[2:] = portfolio[~portfolio['Ticker'].isin(firstsnames)].sort_values(by='Ticker').values\n",
        "# display(portfolio)"
      ],
      "metadata": {
        "id": "T366MMVaumwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Portfolio PERFORMANCE calculation function\n",
        "def portfolio_performance(weights, mu, cov, riskfree):\n",
        "    \"\"\"\n",
        "    Retorna (retorno_portfolio, volatilidade_portfolio, sharpe_portfolio)\n",
        "    expected_returns: vetor de retornos esperados por ativo (numpy array)\n",
        "    cov: matriz de covariância (numpy array)\n",
        "    weights: vetor de pesos\n",
        "    riskfree: taxa livre de risco (mesma periodicidade)\n",
        "    \"\"\"\n",
        "    w = np.array(weights)\n",
        "    ret = float(np.dot(w, mu))\n",
        "    vol = float(np.sqrt(w.T @ cov @ w))\n",
        "    if vol == 0:\n",
        "        sharpe = 0.0\n",
        "    else:\n",
        "        sharpe = (ret - riskfree) / vol\n",
        "    return ret, vol, sharpe"
      ],
      "metadata": {
        "id": "bpOdj8EKhd5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "riskfree = riskfree / 100 # Risk Free is indicated in percentage"
      ],
      "metadata": {
        "id": "Jwb09_JnsmBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = [values / 100 for values in weightport] # Expected Returns are indicated in percentage"
      ],
      "metadata": {
        "id": "41tz294FuOTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert covariance dataframe in numpy matrix\n",
        "cov = covport.values"
      ],
      "metadata": {
        "id": "8Scvi-sRpy8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting expected returns\n",
        "mu = portfolio['RetE%'].values / 100"
      ],
      "metadata": {
        "id": "Jhj-5HIcpryC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Porfolio Expected Return, Expected Risk and Expected Sharpe calculations\n",
        "portfolioretexptotal, portfolioriskexptotal, portfoliosharpeexp = portfolio_performance(weights, mu, cov, riskfree)\n",
        "# print (portfolioretexptotal, portfolioriskexptotal, portfoliosharpeexp)"
      ],
      "metadata": {
        "id": "4-Br_bRqnqxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Portfolio adding columns with Total Return, Total Risk and Sharpe values in first register(in the same line of IBOV value index). Other registers being filled with zero.\n",
        "portfolio['RetET%'] = [portfolioretexptotal * 100] + [0] * (len(portfolio) - 1)\n",
        "portfolio['RetET%'] = portfolio['RetET%'].round(1)\n",
        "portfolio['RiskET%'] = [portfolioriskexptotal * 100] + [0] * (len(portfolio) - 1)\n",
        "portfolio['RiskET%'] = portfolio['RiskET%'].round(0)\n",
        "portfolio['SharpeE'] = [portfoliosharpeexp] + [0] * (len(portfolio) - 1)\n",
        "portfolio['SharpeE'] = portfolio['SharpeE'].round(3)"
      ],
      "metadata": {
        "id": "shtCO9Nl2dSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting real returns\n",
        "mu = portfolio['RetH%'].values / 100"
      ],
      "metadata": {
        "id": "GqMxgTCOZmEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Porfolio Real (historic) Return, Risk and Sharpe calculations\n",
        "portfoliorettotal, portfoliorisktotal, portfoliosharpe = portfolio_performance(weights, mu, cov, riskfree)\n",
        "# print (portfoliorettotal, portfoliorisktotal, portfoliosharpe)"
      ],
      "metadata": {
        "id": "oyK_ofgwZctI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "portfolio['RetHT%'] = [portfoliorettotal * 100] + [0] * (len(portfolio) - 1)\n",
        "portfolio['RetHT%'] = portfolio['RetHT%'].round(1)\n",
        "portfolio['SharpeH'] = [portfoliosharpe] + [0] * (len(portfolio) - 1)\n",
        "portfolio['SharpeH'] = portfolio['SharpeH'].round(3)"
      ],
      "metadata": {
        "id": "ma0xRkeeZYQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Total Beta and add in IBOV line\n",
        "portfolio.at[0, 'Beta'] = (portfolio['W'] / 100 * portfolio['Beta']).sum()\n",
        "portfolio['Beta'] = portfolio['Beta'].round(3)\n",
        "# display(portfolio)"
      ],
      "metadata": {
        "id": "zrwKGlz1YxsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Portfolio MAXIMUM SHARPE calculation function\n",
        "def max_sharpe_weights(mu, cov, risk_free, bounds=None, constraints=None):\n",
        "    \"\"\"\n",
        "    Finds the weights that maximize the Sharpe ratio (using minimize on -sharpe).\n",
        "    bounds: list of tuples (min, max) for each asset. Default: (0,1) for all.\n",
        "    constraints: list of constraint dicts for scipy.optimize.minimize (optional).\n",
        "    Returns the optimization result dictionary and the optimal weights.\n",
        "    \"\"\"\n",
        "    n = len(mu)\n",
        "    if bounds is None:\n",
        "        bounds = tuple((0.0, 1.0) for _ in range(n))\n",
        "    # constraint: sum of weights = 1\n",
        "    cons = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0}]\n",
        "    if constraints:\n",
        "        cons.extend(constraints)\n",
        "    # initialization: equal weights\n",
        "    x0 = np.ones(n) / n\n",
        "\n",
        "    def neg_sharpe(w):\n",
        "        _, _, s = portfolio_performance(w, mu, cov, risk_free)\n",
        "        return -s\n",
        "\n",
        "    res = minimize(neg_sharpe, x0, method='SLSQP', bounds=bounds, constraints=cons)\n",
        "    return res, res.x if res.success else None\n"
      ],
      "metadata": {
        "id": "Mo5XRHm6LR78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting expected returns to calculte Sharpe Maximum\n",
        "mu = portfolio['RetE%'].values / 100"
      ],
      "metadata": {
        "id": "AMi5HgdAdVGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_max, w_max = max_sharpe_weights(mu, cov, riskfree)\n",
        "print(\"Max Sharpe:\", portfolio_performance(w_max, mu, cov, riskfree)[2], \"pesos:\", w_max)\n",
        "# print(\"Ret Max Sharpe:\", w_max)"
      ],
      "metadata": {
        "id": "DO9nFtdx0IG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Add Maximum Sharpe ticker weights to portfolio dataframe\n",
        "portfolio['ShMaxE-W'] = w_max.round(3) * 100\n",
        "# display(portfolio)"
      ],
      "metadata": {
        "id": "kpBjFnaUEZxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add Maximum Sharpe value to portfolio dataframe in the first line\n",
        "portfolio.at[0, 'ShMaxE-W'] = round(portfolio_performance(w_max, mu, cov, riskfree)[2], 3)\n",
        "# display(portfolio)"
      ],
      "metadata": {
        "id": "NajFekHEGdNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add Sharpe Maximum Return column and the value in the first line\n",
        "portfolio['ShMaxRetE%'] = [portfolio_performance(w_max, mu, cov, riskfree)[0] *100] + [0] * (len(portfolio) - 1)\n",
        "portfolio['ShMaxRetE%'] = portfolio['ShMaxRetE%'].round(1)\n",
        "# display(portfolio)"
      ],
      "metadata": {
        "id": "IgOuvel89-d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Portfolio TARGET SHARPE calculation function (adjusted with the use of limitsport)\n",
        "def weights_for_target_sharpe(mu, cov, target_sharpe, riskfree, limitsport, tol=1e-6, maxiter=1000):\n",
        "    \"\"\"\n",
        "    Finds weights that approximate a target Sharpe ratio, using individual limits defined in limitsport.\n",
        "    Minimizes the squared error between Sharpe(weights) and target_sharpe.\n",
        "    \"\"\"\n",
        "\n",
        "    n = len(mu)\n",
        "\n",
        "    # Build bounds using the limits provided by the user (limitsport)\n",
        "    bounds = tuple((0.0, limitsport[i]) for i in range(n))\n",
        "\n",
        "    # Constraint: sum of weights = 1\n",
        "    cons = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0}]\n",
        "\n",
        "    # Initial guess\n",
        "    x0 = np.ones(n) / n\n",
        "\n",
        "    def sharpe_err_sq(w):\n",
        "        _, _, s = portfolio_performance(w, mu, cov, riskfree)\n",
        "        return (s - target_sharpe)**2\n",
        "\n",
        "    opts = {'maxiter': maxiter, 'ftol': tol}\n",
        "    res = minimize(sharpe_err_sq, x0, method='SLSQP', bounds=bounds, constraints=cons, options=opts)\n",
        "\n",
        "    if res.success:\n",
        "        ret, vol, s = portfolio_performance(res.x, mu, cov, riskfree)\n",
        "        info = {'target_sharpe': target_sharpe, 'achieved_sharpe': s, 'ret': ret, 'vol': vol}\n",
        "    else:\n",
        "        info = {'message': res.message}\n",
        "\n",
        "    return res, res.x if res.success else None, info"
      ],
      "metadata": {
        "id": "gFF96qzoLvxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Define here your original list of limits in percentages (example you provided) ---\n",
        "'''limitsport_percent = [0.0, 0.0, 15.0, 15.0, 15.0, 15.0, 5.0, 10.0, 10.0,\n",
        "                      10.0, 5.0, 10.0, 15.0, 5.0, 8.0, 10.0, 5.0, 5.0,\n",
        "                      15.0, 15.0]  # example: values in % (0..100)'''\n",
        "\n",
        "# Convert to fraction (0..1)\n",
        "limitsport = [float(x) / 100.0 for x in limitsassetsport]\n",
        "\n",
        "# Check feasibility: the sum of the maximums must be >= 1 to allow sum(w)=1\n",
        "sum_limits = sum(limitsport)\n",
        "if sum_limits < 1.0 - 1e-12:\n",
        "    # Strategy: scale the limits proportionally until the sum becomes 1.0\n",
        "    # (keeping each limit <= 1.0). This preserves the ratio among limits.\n",
        "    scale = 1.0 / sum_limits\n",
        "    limitsport = [min(1.0, l * scale) for l in limitsport]\n",
        "    print(f\"WARNING: sum of limits < 1.0 — limits scaled proportionally (scale={scale:.6f}) to make the problem feasible.\")\n",
        "    # recompute sum for information\n",
        "    print(\"New limits (fraction):\", limitsport)\n",
        "    print(\"Sum of new limits:\", sum(limitsport))\n",
        "\n",
        "# Define the target (your code)\n",
        "# Target as a percentage of ShMaxE-W\n",
        "target = portfolio.at[0, 'ShMaxE-W'] * target_per / 100\n",
        "print(\"Target:\", target)\n",
        "\n",
        "# CORRECT call: pass limitsport (in fraction 0..1) as argument\n",
        "res_tgt, w_tgt, info = weights_for_target_sharpe(mu, cov, target, riskfree, limitsport)\n",
        "\n",
        "# Debug/output (optional)\n",
        "# print(\"Target result:\", info)\n",
        "# print(\"Weights:\", w_tgt)\n",
        "# print(\"Achieved Sharpe:\", info.get('achieved_sharpe'))"
      ],
      "metadata": {
        "id": "ZlKAfYzCNojC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Add Target Sharpe ticker weights to portfolio dataframe\n",
        "portfolio['ShTg-W'] = (w_tgt * 100).round(3)\n",
        "# Add Target (Achieved) Sharpe value to portfolio dataframe in the first line\n",
        "portfolio.at[0, 'ShTg-W'] = round(info['achieved_sharpe'], 3)\n",
        "# Add Target Maximum Return column and the value in the first line\n",
        "portfolio['ShTgRetE%'] = [portfolio_performance(w_tgt, mu, cov, riskfree)[0] *100] + [0] * (len(portfolio) - 1)\n",
        "portfolio['ShTgRetE%'] = portfolio['ShTgRetE%'].round(1)\n",
        "display(portfolio)"
      ],
      "metadata": {
        "id": "urDEchwGUwei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODQ2jlYnQjNS"
      },
      "outputs": [],
      "source": [
        "# Autentication in Google Docs (only once)\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyqrePZyZtys"
      },
      "outputs": [],
      "source": [
        "# Open workbook and worksheets\n",
        "wb = gc.open('Quotes')\n",
        "wss = wb.worksheet('Stockvar')\n",
        "wsr = wb.worksheet('RealStatevar')\n",
        "wssus = wb.worksheet('StockUSvar')\n",
        "wseus = wb.worksheet('ETFUSvar')\n",
        "wsrus = wb.worksheet('RealStateUSvar')\n",
        "wsport = wb.worksheet('Portfolio')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjSeVpqvaYkH"
      },
      "outputs": [],
      "source": [
        "# Write data in the worksheets\n",
        "wss.update([stockvar.columns.values.tolist()] + stockvar.values.tolist())\n",
        "wsr.update([realstatevar.columns.values.tolist()] + realstatevar.values.tolist())\n",
        "wssus.update([stockusvar.columns.values.tolist()] + stockusvar.values.tolist())\n",
        "wseus.update([etfusvar.columns.values.tolist()] + etfusvar.values.tolist())\n",
        "wsrus.update([reitusvar.columns.values.tolist()] + reitusvar.values.tolist())\n",
        "wsport.update([portfolio.columns.values.tolist()] + portfolio.values.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# B3 REAL STATE FUNDS EXPLORER ROUTINE\n",
        "#\n",
        "# example tickerr = ['IFIX.SA','BTLG11.SA','HGCR11.SA','HGBS11.SA','HGRE11.SA','HGRU11.SA','HSLG11.SA','HSML11.SA','HTMX11.SA','JSAF11.SA','JFLL11.SA','KNCA11.SA','KNHF11.SA','KNIP11.SA','MALL11.SA','MFII11.SA','SADI11.SA','TGAR11.SA','TRXF11.SA','VGHF11.SA','VISC11.SA']\n",
        "# Remove \".SA\" from real state funds dataframe tickers\n",
        "tickerradjusted = [nome.replace('.SA', '') for nome in tickerr]\n",
        "# Remove \"IFIX\" ticker\n",
        "if \"IFIX\" in tickerradjusted:\n",
        "    tickerradjusted.remove(\"IFIX\")\n",
        "#\n",
        "# Funds list filter, exclude tickers not in real state funds list\n",
        "fundsexplorer = fundsexplorer[fundsexplorer['Fundos'].isin(tickerradjusted)]\n",
        "# display(fundsexplorer)\n",
        "#\n",
        "# Open worksheet\n",
        "wsrfunds = wb.worksheet('FundsExplorer')\n",
        "# Open worksheet\n",
        "wsrfunds = wb.worksheet('FundsExplorer')"
      ],
      "metadata": {
        "id": "lIdkgEQpBJ2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# US STOCKS YAHOO FINANCE ROUTINE\n",
        "#\n",
        "# Example: tickersus = ['^GSPC','USDBRL=X','AAPL','AIG','BAC','RIO','DHI','EXC','KMB','KO','LOPE','LYB','MGA','MSFT','MSTR','NUE','NVDA','TGT','TMUS','UPS','UNH','XOM']\n",
        "#\n",
        "# Dictionary to store the data (each value is a dict for each ticker)\n",
        "yfstockusdata = {}\n",
        "\n",
        "# Set to accumulate all keys found across all tickers\n",
        "all_keys = set()\n",
        "\n",
        "for t in tickersus:\n",
        "    try:\n",
        "        tk = yf.Ticker(t)\n",
        "        info = tk.info or {}\n",
        "        # Ensures the ticker is always present as a field\n",
        "        info_row = {'Ticker': t}\n",
        "        # Add all key/value pairs returned by .info\n",
        "        for k, v in info.items():\n",
        "            info_row[k] = v\n",
        "            all_keys.add(k)\n",
        "        # Store the row\n",
        "        yfstockusdata[t] = info_row\n",
        "    except Exception as e:\n",
        "        # In case of failure, register the ticker with only the 'Ticker' field\n",
        "        # and leave the remaining keys absent (they will become NaN in the DataFrame)\n",
        "        yfstockusdata[t] = {'Ticker': t}\n",
        "        # (optional) you may log the error if needed:\n",
        "        # print(f\"Error for {t}: {e}\")\n",
        "\n",
        "# To guarantee ordered columns with 'Ticker' first,\n",
        "# we explicitly build the list of columns\n",
        "cols_other = sorted(all_keys - {'Ticker'})  # alphabetical sorting of other keys (optional)\n",
        "cols_final = ['Ticker'] + cols_other\n",
        "\n",
        "# Convert the dictionary to a DataFrame keeping numeric index (0,1,2,...)\n",
        "# Note: using list(yfstockusdata.values()) to keep each dict as one row\n",
        "yfstockus = pd.DataFrame(list(yfstockusdata.values()))\n",
        "\n",
        "# Reindex columns to ensure 'Ticker' first and all remaining columns included\n",
        "# Some keys might not appear in all tickers — this will not happen for missing keys,\n",
        "# because all_keys was built from .info for each ticker.\n",
        "# However, just to be safe:\n",
        "existing_cols = [c for c in cols_final if c in yfstockus.columns]\n",
        "yfstockus = yfstockus[existing_cols + [c for c in yfstockus.columns if c not in existing_cols]]\n",
        "\n",
        "# Display the DataFrame (Jupyter/IPython)\n",
        "# display(yfstockus)"
      ],
      "metadata": {
        "id": "6x6hp3-7KNvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Renaming ^GSPC to SP500 and USDBRLX to USDBRL\n",
        "yfstockus['Ticker'] = yfstockus['Ticker'].str.replace('^GSPC', 'SP500', regex=False)\n",
        "yfstockus['Ticker'] = yfstockus['Ticker'].str.replace('USDBRL=X', 'USDBRL', regex=False)\n",
        "# display(yfstockus)"
      ],
      "metadata": {
        "id": "KaMUmbkGL_wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Value sanitization function ---\n",
        "def sanitize_value(v, maxlen=500):\n",
        "    # None / NaN\n",
        "    if v is None:\n",
        "        return ''\n",
        "    # floats: reject NaN/Inf\n",
        "    if isinstance(v, float):\n",
        "        if not np.isfinite(v):\n",
        "            return ''\n",
        "        return float(v)\n",
        "    # integers and booleans are OK\n",
        "    if isinstance(v, (int, bool, np.integer, np.bool_)):\n",
        "        return int(v) if isinstance(v, (int, np.integer)) else bool(v)\n",
        "    # short strings are OK (truncate if too long)\n",
        "    if isinstance(v, str):\n",
        "        return v if len(v) <= maxlen else v[:maxlen]\n",
        "    # time series / numpy types converted to truncated string\n",
        "    # for all other types (dict, list, Timestamp, ndarray, Decimal, etc.)\n",
        "    try:\n",
        "        s = str(v)\n",
        "        return s if len(s) <= maxlen else s[:maxlen]\n",
        "    except Exception:\n",
        "        return ''\n",
        "\n",
        "# --- Sanitize column by column using Series.map (avoids applymap) ---\n",
        "yfstockus_sanitized = yfstockus.copy()\n",
        "\n",
        "for col in yfstockus_sanitized.columns:\n",
        "    # Use map to apply the function in a vectorized way per column\n",
        "    yfstockus_sanitized[col] = yfstockus_sanitized[col].map(lambda x: sanitize_value(x))\n",
        "\n",
        "# --- Build the rows to send to Google Sheets ---\n",
        "rows = [yfstockus_sanitized.columns.tolist()] + yfstockus_sanitized.values.tolist()\n",
        "\n",
        "# --- Open/Create worksheet and update ---\n",
        "try:\n",
        "    wssyfstockus = wb.worksheet('YFStockUS')\n",
        "except Exception as e:\n",
        "    # if it does not exist, create it (adjust rows/cols if you want a specific size)\n",
        "    wssyfstockus = wb.add_worksheet(title='YFStockUS', rows=str(len(rows)+10), cols=str(len(rows[0])+5))\n",
        "\n",
        "# Perform the update (now with serializable data)\n",
        "wssyfstockus.update(rows)"
      ],
      "metadata": {
        "id": "6iveMFF-Mvnr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLdpmoC9MhgoV89jDvlBkC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}